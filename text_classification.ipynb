{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW, Trainer, TrainingArguments, EarlyStoppingCallback\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from bert_score import score\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 2: Load and Preprocess Data\n",
    "\n",
    "# Load the data\n",
    "train_essays = pd.read_csv('train_essays.csv')\n",
    "train_prompts = pd.read_csv('train_prompts.csv')\n",
    "\n",
    "# Combine the essays and prompts based on prompt_id\n",
    "train_data = pd.merge(train_essays, train_prompts, on='prompt_id')\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "class EssayDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=256):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['text']\n",
    "        label = self.data.iloc[idx]['generated']\n",
    "\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Set up training parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the BERT model with dropout regularization\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Data augmentation\n",
    "aug = naw.SynonymAug(aug_src='wordnet')\n",
    "\n",
    "# Apply data augmentation to the training data\n",
    "train_data_augmented = train_data.copy()\n",
    "train_data_augmented['text'] = train_data_augmented['text'].apply(lambda x: aug.augment(x))\n",
    "\n",
    "# Combine the augmented data with the original training data\n",
    "train_data = pd.concat([train_data, train_data_augmented], ignore_index=True)\n",
    "\n",
    "# Create the training and validation datasets\n",
    "train_dataset = EssayDataset(train_data, tokenizer)\n",
    "val_dataset = EssayDataset(val_data, tokenizer)\n",
    "\n",
    "# Define the fitness function for PSO\n",
    "def fitness_function(params):\n",
    "    learning_rate, num_train_epochs = params\n",
    "\n",
    "    # Add dropout to the BERT model\n",
    "    model.config.attention_probs_dropout_prob = 0.1\n",
    "    model.config.hidden_dropout_prob = 0.1\n",
    "\n",
    "    # Add weight decay to the optimizer\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01, correct_bias=False)\n",
    "\n",
    "    # Create the training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        warmup_steps=500,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy='steps',\n",
    "        eval_steps=500,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_loss',\n",
    "        greater_is_better=False,\n",
    "        save_total_limit=1\n",
    "    )\n",
    "\n",
    "    # Create the trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.02)],\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Evaluate the model\n",
    "    eval_results = trainer.evaluate()\n",
    "\n",
    "    # Display the evaluation results\n",
    "    print(\"Evaluation Results:\", eval_results)\n",
    "\n",
    "    # Return the validation loss\n",
    "    return -eval_results.get(\"eval_acc\", 0)  # Use get method to handle the KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bounds for PSO\n",
    "lower_bound = [1e-6, 1]  # Lower bound for learning rate and num_train_epochs\n",
    "upper_bound = [1e-2, 5]  # Upper bound for learning rate and num_train_epochs\n",
    "\n",
    "# Perform PSO optimization\n",
    "best_params, _ = pso(fitness_function, lower_bound, upper_bound, swarmsize=5, maxiter=10)\n",
    "print(\"Best Hyperparameters found by PSO:\")\n",
    "print(f\"Learning Rate: {best_params[0]}\")\n",
    "print(f\"Num Train Epochs: {int(best_params[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=best_params[0], weight_decay=0.01, correct_bias=False)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./bert_model\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_total_limit=1,\n",
    "    num_train_epochs=int(best_params[1]),\n",
    "    save_steps=500,\n",
    "    logging_steps=100,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    report_to=\"tensorboard\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TensorBoard SummaryWriter\n",
    "writer = SummaryWriter(log_dir=\"./logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=EssayDataset(train_data, tokenizer),\n",
    "    eval_dataset=EssayDataset(val_data, tokenizer),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=None,\n",
    "    compute_metrics=None,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.02)],\n",
    "    optimizers=(optimizer, None)\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "trainer.save_model(\"./bert_model\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# Calculate accuracy\n",
    "predictions = trainer.predict(EssayDataset(val_data, tokenizer))\n",
    "predicted_labels = predictions.predictions.argmax(axis=1)\n",
    "true_labels = val_data['generated'].values\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "# Calculate BERTScore\n",
    "P, R, F1 = score(hyps, refs, lang=\"en\", verbose=True)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(\"***** Evaluation Results *****\")\n",
    "print(f\"Validation Accuracy: {accuracy}\")\n",
    "print(f\"BERTScore Precision: {P.mean().item():.4f}\")\n",
    "print(f\"BERTScore Recall: {R.mean().item():.4f}\")\n",
    "print(f\"BERTScore F1: {F1.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model using BERTScore\n",
    "val_dataset = EssayDataset(val_data, tokenizer)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "refs = [ref['text'].tolist() for _, ref in val_data.groupby('id')]\n",
    "hyps = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(val_dataloader, desc='Validation'):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "        hyps.extend([tokenizer.decode(ids, skip_special_tokens=True) for ids in input_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate BERTScore\n",
    "P, R, F1 = score(hyps, refs, lang=\"en\", verbose=True)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(f\"BERTScore Precision: {P.mean().item():.4f}\")\n",
    "print(f\"BERTScore Recall: {R.mean().item():.4f}\")\n",
    "print(f\"BERTScore F1: {F1.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the test data\n",
    "test_essays = pd.read_csv('test_essays.csv')\n",
    "\n",
    "# Load the trained model\n",
    "model = BertForSequenceClassification.from_pretrained('./bert_model')  # Change the path accordingly\n",
    "tokenizer = BertTokenizer.from_pretrained('./bert_model')  # Change the path accordingly\n",
    "\n",
    "# Preprocess the test data\n",
    "class EssayTestDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=256):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data.iloc[idx]['text']\n",
    "\n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        }\n",
    "\n",
    "# Create a DataLoader for the test data\n",
    "test_dataset = EssayTestDataset(test_essays, tokenizer)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_dataloader, desc='Predicting'):\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        batch_predictions = torch.argmax(logits, dim=1)\n",
    "\n",
    "        predictions.extend(batch_predictions.cpu().numpy())\n",
    "\n",
    "# Add predictions to the test data\n",
    "test_essays['predicted'] = predictions\n",
    "\n",
    "# Display the predictions\n",
    "print(test_essays[['id', 'predicted']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
